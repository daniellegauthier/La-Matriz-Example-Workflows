{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec0767-04f4-411d-9965-f014bb319c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy torch transformers sentence-transformers gradio spacy nltk pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc26bef-fe87-4af0-b683-689a527b40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import nltk, spacy, torch, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import gradio as gr\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# -------------------- setup --------------------\n",
    "def ensure_spacy():\n",
    "    try:\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "    except Exception:\n",
    "        import spacy.cli\n",
    "        spacy.cli.download(\"en_core_web_sm\")\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def ensure_nltk():\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/punkt\")\n",
    "    except LookupError:\n",
    "        nltk.download(\"punkt\")\n",
    "\n",
    "ensure_nltk()\n",
    "nlp = ensure_spacy()\n",
    "\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "bert_sentiment = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "emotion_model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "emotion_tokenizer = AutoTokenizer.from_pretrained(emotion_model_name)\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(emotion_model_name)\n",
    "\n",
    "# -------------------- constants --------------------\n",
    "CSV_PATH_PLUS  = \"la matrice plus.csv\"   # pathways + colors + template words\n",
    "CSV_PATH_COLOR = \"la matrice.csv\"        # color lexicon\n",
    "\n",
    "SEQUENCE_ALIASES = {\n",
    "    \"Direct\": \"direct\",\n",
    "    \"Feminine\": \"feminine\",\n",
    "    \"Knot\": \"knot\",\n",
    "    \"Masculine\": \"masc\",\n",
    "    \"Pain\": \"pain\",\n",
    "    \"Prayer\": \"prayer\",\n",
    "    \"Precise\": \"precise\",\n",
    "    \"Practical\": \"practical\",\n",
    "    \"Plot\": \"plot\",\n",
    "    \"Spiritual\": \"spiritual\",\n",
    "    \"Sad\": \"sad\",\n",
    "}\n",
    "\n",
    "SEQUENCE_IMAGE_FILES = {\n",
    "    \"direct\": \"direct pathway.png\",\n",
    "    \"feminine\": \"fem pathway.png\",\n",
    "    \"knot\": \"knot pathway.png\",\n",
    "    \"masc\": \"masc pathway.png\",\n",
    "    \"pain\": \"pain pathway.png\",\n",
    "    \"prayer\": \"prayer pathway.png\",\n",
    "    \"precise\": \"precise pathway.png\",\n",
    "    \"practical\": \"practical pathway.png\",\n",
    "    \"plot\": \"plot pathway.png\",\n",
    "    \"spiritual\": \"spiritual pathway.png\",\n",
    "    \"sad\": \"sad pathway.png\"\n",
    "}\n",
    "\n",
    "GNH_DOMAINS: Dict[str, str] = {\n",
    "    \"Mental Wellness\": \"mental health, emotional clarity, peace of mind\",\n",
    "    \"Social Wellness\": \"relationships, community, friendship, social harmony\",\n",
    "    \"Economic Wellness\": \"income, savings, financial stability, cost of living\",\n",
    "    \"Workplace Wellness\": \"career, work-life balance, promotion, productivity\",\n",
    "    \"Physical Wellness\": \"physical health, sleep, fitness, exercise\",\n",
    "    \"Environmental Wellness\": \"green space, nature, environmental care\",\n",
    "    \"Health\": \"healthcare, medical care, recovery, well-being\",\n",
    "    \"Education Value\": \"learning, education, school, knowledge, wisdom\",\n",
    "    \"Good Governance\": \"freedom, justice, fairness, democratic participation\",\n",
    "    \"Living Standards\": \"housing, wealth, basic needs, affordability\",\n",
    "    \"Cultural Diversity\": \"tradition, language, cultural expression, heritage\",\n",
    "    \"Political Wellness\": \"rights, law, free speech, civic participation\",\n",
    "    \"Ecological Diversity\": \"biodiversity, forest, ecosystem, wildlife\",\n",
    "}\n",
    "\n",
    "GNH_COLORS: Dict[str, str] = {\n",
    "    \"Economic Wellness\": \"#808080\",\n",
    "    \"Mental Wellness\": \"#FA005A\",\n",
    "    \"Workplace Wellness\": \"#ffd700\",\n",
    "    \"Physical Wellness\": \"#FAB478\",\n",
    "    \"Social Wellness\": \"#ffa500\",\n",
    "    \"Political Wellness\": \"#ffffff\",\n",
    "    \"Environmental Wellness\": \"#0000FF\",\n",
    "    \"Ecological Diversity\": \"#00FF00\",\n",
    "    \"Health\": \"#FF0000\",\n",
    "    \"Good Governance\": \"#000000\",\n",
    "    \"Education Value\": \"#8b4513\",\n",
    "    \"Living Standards\": \"#ffff00\",\n",
    "    \"Cultural Diversity\": \"#B432FF\",\n",
    "}\n",
    "\n",
    "WORD_MODES = [\"Receiver\", \"Transmitter\", \"English Words\", \"GNH Indicators\", \"Keys\", \"Sound\"]\n",
    "\n",
    "MODE_TO_LEX_KEY = {\n",
    "    \"receiver\": \"receiver\",\n",
    "    \"transmitter\": \"transmitter\",\n",
    "    \"english words\": \"english-words\",\n",
    "    \"gnh indicators\": \"gnh-indicator\",\n",
    "    \"keys\": \"key\",\n",
    "    \"sound\": \"sound\",\n",
    "}\n",
    "\n",
    "MAX_COLORS = 8\n",
    "\n",
    "# -------------------- loaders --------------------\n",
    "def _find_col(df: pd.DataFrame, candidates: List[str]) -> str | None:\n",
    "    names = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c.lower() in names: return names[c.lower()]\n",
    "    for want in candidates:\n",
    "        ww = want.replace(\" \", \"\").replace(\"-\", \"\")\n",
    "        for lc, orig in names.items():\n",
    "            if ww in lc.replace(\" \", \"\").replace(\"-\", \"\"):\n",
    "                return orig\n",
    "    return None\n",
    "\n",
    "def load_pathway_info(csv_path_plus: str):\n",
    "    df = pd.read_csv(csv_path_plus)\n",
    "    keys = set(SEQUENCE_ALIASES.values())\n",
    "    rows = df[df[\"color\"].astype(str).str.lower().isin(keys)].copy()\n",
    "\n",
    "    seq_to_colors: Dict[str, List[str]] = {}\n",
    "    seq_phrase: Dict[str, str] = {}\n",
    "\n",
    "    # colors live in 'r' (list), template = concat of the other fields\n",
    "    cols_for_phrase = [c for c in df.columns if c not in (\"color\", \"r\", \"g\", \"b\")]\n",
    "    for _, row in rows.iterrows():\n",
    "        key = str(row[\"color\"]).strip().lower()\n",
    "        color_list = str(row.get(\"r\", \"\") or \"\")\n",
    "        colors = [c.strip().lower() for c in re.split(r\"[,\\s]+\", color_list) if c.strip()]\n",
    "        seq_to_colors[key] = list(dict.fromkeys(colors))\n",
    "\n",
    "        vals = []\n",
    "        for c in cols_for_phrase:\n",
    "            v = row.get(c)\n",
    "            if pd.notna(v):\n",
    "                s = str(v).strip()\n",
    "                if s and s.lower() != \"nan\":\n",
    "                    vals.append(s)\n",
    "        phrase = \" \".join(\" \".join(vals).split())  # base template\n",
    "        seq_phrase[key] = phrase\n",
    "\n",
    "    return seq_to_colors, seq_phrase\n",
    "\n",
    "def _split_words(s: str) -> List[str]:\n",
    "    if not isinstance(s, str): return []\n",
    "    parts = re.split(r\"[,\\;/\\|\\s]+\", s.strip())\n",
    "    return [p for p in (w.strip().lower() for w in parts) if p]\n",
    "\n",
    "def load_color_lexicon(csv_path_color: str):\n",
    "    df = pd.read_csv(csv_path_color)\n",
    "    color_col = _find_col(df, [\"color\", \"colour\"])\n",
    "    r_col = _find_col(df, [\"receiver\"])\n",
    "    t_col  = _find_col(df, [\"transmitter\"])\n",
    "    en_col = _find_col(df, [\"english-words\"])\n",
    "    gnh_col  = _find_col(df, [\"gnh-indicator\"])\n",
    "    k_col  = _find_col(df, [\"key\"])\n",
    "    s_col  = _find_col(df, [\"sound\"])\n",
    "\n",
    "    lex: Dict[str, Dict[str, str]] = {}\n",
    "    for _, row in df.iterrows():\n",
    "        cname = str(row.get(color_col, \"\")).strip().lower()\n",
    "        if not cname: \n",
    "            continue\n",
    "        lex[cname] = {\n",
    "            \"receiver\": str(row.get(r_col, \"\") or \"\").strip(),\n",
    "            \"transmitter\": str(row.get(t_col, \"\") or \"\").strip(),\n",
    "            \"english-words\": str(row.get(en_col, \"\") or \"\").strip(),\n",
    "            \"gnh-indicator\": str(row.get(gnh_col, \"\") or \"\").strip(),\n",
    "            \"key\": str(row.get(k_col, \"\") or \"\").strip(),\n",
    "            \"sound\": str(row.get(s_col, \"\") or \"\").strip()\n",
    "        }\n",
    "    return lex\n",
    "\n",
    "\n",
    "SEQ_TO_COLORS, SEQ_PHRASE = load_pathway_info(CSV_PATH_PLUS)\n",
    "COLOR_LEX = load_color_lexicon(CSV_PATH_COLOR)\n",
    "\n",
    "def sequence_to_image_path(seq_key: str) -> str | None:\n",
    "    fname = SEQUENCE_IMAGE_FILES.get(seq_key)\n",
    "    return fname if (fname and os.path.exists(fname)) else None\n",
    "\n",
    "# -------------------- NLP helpers --------------------\n",
    "def encode_text(t: str):\n",
    "    return sbert_model.encode(t, convert_to_tensor=True)\n",
    "\n",
    "def classify_emotion(text: str) -> Tuple[str, float]:\n",
    "    inputs = emotion_tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = emotion_model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=1).squeeze()\n",
    "    labels = emotion_model.config.id2label\n",
    "    idx = int(torch.argmax(probs).item())\n",
    "    return labels[idx], float(probs[idx].item())\n",
    "\n",
    "def score_sentiment(text: str) -> float:\n",
    "    out = bert_sentiment(text[:512])[0]\n",
    "    label, score = out[\"label\"], out[\"score\"]\n",
    "    scaled = 5 + 5 * score if label == \"POSITIVE\" else 1 + 4 * (1 - score)\n",
    "    return round(min(10, max(1, scaled)), 2)\n",
    "\n",
    "def score_accomplishment(text: str) -> float:\n",
    "    doc = nlp(text); score = 5.0\n",
    "    key_phrases = {\"finally\",\"told\",\"decided\",\"quit\",\"refused\",\"stood\",\"walked\",\"walked away\",\"returned\",\"return\"}\n",
    "    for token in doc:\n",
    "        if token.text.lower() in key_phrases: score += 1.5\n",
    "        if token.tag_ in {\"VBD\",\"VBN\"}:       score += 0.5\n",
    "    return round(min(10, max(1, score)), 2)\n",
    "\n",
    "def semantic_indicator_mapping(text: str, sentiment_score: float, sentiment_weight: float = 0.3) -> Dict[str, float]:\n",
    "    v = encode_text(text)\n",
    "    out: Dict[str, float] = {}\n",
    "    for dom, desc in GNH_DOMAINS.items():\n",
    "        sim = float(util.cos_sim(v, encode_text(desc)).item())\n",
    "        sim = max(0.0, min(1.0, sim))\n",
    "        blended = (1 - sentiment_weight) * sim + sentiment_weight * (sentiment_score / 10.0)\n",
    "        out[dom] = round(blended, 3)\n",
    "    return dict(sorted(out.items(), key=lambda kv: -kv[1]))\n",
    "\n",
    "def indicators_plot(indicators: Dict[str, float]):\n",
    "    labels = list(indicators.keys()); values = list(indicators.values())\n",
    "    colors = [GNH_COLORS.get(label, \"#cccccc\") for label in labels]\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    plt.barh(labels, values, color=colors)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"GNH Indicator Similarity\")\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# -------------------- prompt building (legible placeholders) --------------------\n",
    "def join_all_words(color: str) -> List[str]:\n",
    "    d = COLOR_LEX.get(color.lower(), {})\n",
    "    return list(dict.fromkeys(d.get(\"receiver\", []) + d.get(\"transmitter\", []) + d.get(\"english-words\", []) + d.get(\"gnh-indicator\", []) + d.get(\"key\", []) + d.get(\"sound\", [])))\n",
    "\n",
    "def nearest_gnh_domain_for_color(color: str) -> Tuple[str, float]:\n",
    "    words = \" \".join(join_all_words(color))\n",
    "    if not words:\n",
    "        return \"Mental Wellness\", 0.0\n",
    "    v = encode_text(words)\n",
    "    best, best_sim = None, -1.0\n",
    "    for dom, desc in GNH_DOMAINS.items():\n",
    "        sim = float(util.cos_sim(v, encode_text(desc)).item())\n",
    "        if sim > best_sim:\n",
    "            best, best_sim = dom, sim\n",
    "    return best or \"Mental Wellness\", best_sim\n",
    "\n",
    "def labels_for_mode(colors: List[str], mode: str) -> List[str]:\n",
    "    if mode.lower().startswith(\"gnh\"):\n",
    "        return [nearest_gnh_domain_for_color(c)[0] for c in colors]\n",
    "    return [c.capitalize() for c in colors]\n",
    "    \n",
    "def placeholder_for(color: str, mode: str) -> str:\n",
    "    \"\"\"\n",
    "    Placeholder directly from the CSV column corresponding to the word mode.\n",
    "    \"\"\"\n",
    "    if not color or not mode:\n",
    "        return \"\"\n",
    "    \n",
    "    color_lc = color.lower()\n",
    "    mode_key = MODE_TO_LEX_KEY.get(mode.lower())\n",
    "    if not mode_key:\n",
    "        return \"\"\n",
    "\n",
    "    lex_entry = COLOR_LEX.get(color_lc)\n",
    "    if not lex_entry:\n",
    "        return \"\"\n",
    "\n",
    "    placeholder_text = lex_entry.get(mode_key, \"\")\n",
    "    return placeholder_text\n",
    "\n",
    "\n",
    "def simple_color_legend(colors: List[str]) -> str:\n",
    "    if not colors:\n",
    "        return \"No prompts available for this pathway.\"\n",
    "    parts = []\n",
    "    for c in colors:\n",
    "        dot = f\"<span style='display:inline-block;width:10px;height:10px;border-radius:50%;background:{c};margin-right:8px;border:1px solid #999;vertical-align:middle'></span>\"\n",
    "        parts.append(f\"<div style='margin:4px 0'>{dot}<b>{c.capitalize()}</b></div>\")\n",
    "    return \"<div>\" + \"\".join(parts) + \"</div>\"\n",
    "\n",
    "def colors_for_sequence(seq_key: str) -> List[str]:\n",
    "    return SEQ_TO_COLORS.get(seq_key, [])\n",
    "\n",
    "def update_prompt_ui(seq_choice: str, word_mode: str, *current_values):\n",
    "    \"\"\"\n",
    "    Updates the color input boxes:\n",
    "      - Label = \"ColorName meaning\"\n",
    "      - Placeholder = CSV words for chosen word mode\n",
    "      - PRESERVES current values when just changing mode\n",
    "    \"\"\"\n",
    "    key = SEQUENCE_ALIASES.get(seq_choice)\n",
    "    colors = colors_for_sequence(key)\n",
    "    legend_html = simple_color_legend(colors)\n",
    "\n",
    "    updates = []\n",
    "    for i in range(MAX_COLORS):\n",
    "        if i < len(colors):\n",
    "            color_name = colors[i].capitalize()\n",
    "            ph = placeholder_for(colors[i], word_mode)\n",
    "            # Preserve existing value if available\n",
    "            current_val = current_values[i] if i < len(current_values) else \"\"\n",
    "            updates.append(gr.update(visible=True, label=f\"{color_name} meaning\", placeholder=ph, value=current_val))\n",
    "        else:\n",
    "            updates.append(gr.update(visible=False, value=\"\", label=f\"Input {i+1}\", placeholder=\"â€”\"))\n",
    "    return (legend_html, *updates)\n",
    "\n",
    "# -------------------- template replacement --------------------\n",
    "def render_phrase_template(base_phrase: str, colors: List[str], labels: List[str], inputs: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Replace occurrences of '<color>-pathway' (any spacing/hyphen variants) with the user's phrase for that color.\n",
    "    If user left it empty, keep the label (color name or mapped GNH indicator).\n",
    "    Finally, append a compact legend ' // Label: input'.\n",
    "    \"\"\"\n",
    "    text = base_phrase or \"\"\n",
    "    # build replacement map color -> replacement text\n",
    "    rep: Dict[str, str] = {}\n",
    "    for color, label, user in zip(colors, labels, inputs):\n",
    "        use = user.strip() if isinstance(user, str) and user.strip() else label\n",
    "        rep[color.lower()] = use\n",
    "\n",
    "    # replace each token case-insensitively\n",
    "    for color, replacement in rep.items():\n",
    "        # match 'brown-pathway', 'brown pathway', 'Brown- Pathway', etc.\n",
    "        pattern = re.compile(rf\"\\b{re.escape(color)}\\s*-\\s*pathway\\b\", re.IGNORECASE)\n",
    "        text = pattern.sub(replacement, text)\n",
    "\n",
    "    # if the template had no tokens, fall back to readable construction:\n",
    "    # \"use A to B the C of D as a new E\" is preserved, but we still append meanings\n",
    "    suffix_parts = []\n",
    "    for color, label, user in zip(colors, labels, inputs):\n",
    "        if isinstance(user, str) and user.strip():\n",
    "            suffix_parts.append(f\"{label}: {user.strip()}\")\n",
    "    if suffix_parts:\n",
    "        text = (text + \" // \" + \" // \".join(suffix_parts)).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# -------------------- main analysis --------------------\n",
    "def analyze(text: str, seq_choice: str, word_mode: str, *color_inputs):\n",
    "    key = SEQUENCE_ALIASES.get(seq_choice)\n",
    "    if key not in SEQ_PHRASE:\n",
    "        return (5.0, \"neutral (0.0)\", 5.0, \"Choose a valid pathway.\", \"{}\", None, None, f\"{seq_choice} (unavailable)\",\n",
    "                *update_prompt_ui(seq_choice, word_mode, *color_inputs))\n",
    "\n",
    "    colors = colors_for_sequence(key)\n",
    "    labels = labels_for_mode(colors, word_mode)\n",
    "    base_phrase = SEQ_PHRASE.get(key, \"\")\n",
    "\n",
    "    # updated phrase with template replacement\n",
    "    user_inputs = list(color_inputs)[:len(colors)]\n",
    "    updated_phrase = render_phrase_template(base_phrase, colors, labels, user_inputs)\n",
    "\n",
    "    # analysis on original + updated\n",
    "    combined_text = \" \".join([t for t in [text, updated_phrase] if t and t.strip()])\n",
    "    sentiment = score_sentiment(combined_text)\n",
    "    emotion, emo_conf = classify_emotion(combined_text)\n",
    "    accomplishment = score_accomplishment(combined_text)\n",
    "\n",
    "    indicators = semantic_indicator_mapping(combined_text, sentiment_score=sentiment)\n",
    "    fig = indicators_plot(indicators)\n",
    "    top5 = list(indicators.items())[:5]\n",
    "    top5_str = \"\\n\".join(f\"{k}: {v}\" for k, v in top5)\n",
    "\n",
    "    img_path = sequence_to_image_path(key)\n",
    "    meta = f\"{key} | colors: {', '.join(colors) if colors else 'â€”'}\"\n",
    "    emo_str = f\"{emotion} ({emo_conf:.3f})\"\n",
    "\n",
    "    # keep prompt area synced - PRESERVE user inputs\n",
    "    prompt_updates = update_prompt_ui(seq_choice, word_mode, *color_inputs)\n",
    "\n",
    "    return (\n",
    "        sentiment, emo_str, accomplishment,\n",
    "        updated_phrase, top5_str, fig, img_path, meta,\n",
    "        *prompt_updates\n",
    "    )\n",
    "\n",
    "# -------------------- UI --------------------\n",
    "SEQ_CHOICES = list(SEQUENCE_ALIASES.keys())\n",
    "DEFAULT_SEQ = \"Knot\" if \"Knot\" in SEQ_CHOICES else SEQ_CHOICES[0]\n",
    "\n",
    "with gr.Blocks(title=\"RGB Root Matriz Color Plotter\") as demo:\n",
    "    gr.Markdown(\"## RGB Root Matriz Color Plotter\\n\"\n",
    "                \"Type a phrase. Choose a **Sequence**. \"\n",
    "                \"You'll get sentiment, emotion, accomplishment, GNH bars, and the pathway phrase + image from the dataset.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        inp = gr.Textbox(lines=4, label=\"Your situation / obstacle\", placeholder=\"Describe the situation...\")\n",
    "\n",
    "    with gr.Row():\n",
    "        seq = gr.Dropdown(choices=SEQ_CHOICES, value=DEFAULT_SEQ, label=\"Pathway\")\n",
    "        word_mode = gr.Radio(choices=WORD_MODES, value=\"Receiver\", label=\"Word Mode\")\n",
    "\n",
    "    legend = gr.HTML()\n",
    "\n",
    "    color_boxes: List[gr.Textbox] = []\n",
    "    for i in range(MAX_COLORS):\n",
    "        color_boxes.append(\n",
    "            gr.Textbox(\n",
    "                visible=True,          # MUST be True initially\n",
    "                label=f\"Input {i+1}\",\n",
    "                placeholder=\"â€”\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    run = gr.Button(\"Generate Pathway Analysis\", variant=\"primary\")\n",
    "\n",
    "    with gr.Row():\n",
    "        sent = gr.Number(label=\"Sentiment (1â€“10)\")\n",
    "        emo  = gr.Text(label=\"Emotion\")\n",
    "        acc  = gr.Number(label=\"Accomplishment (1â€“10)\")\n",
    "\n",
    "    with gr.Row():\n",
    "        phrase_out = gr.Text(label=\"Updated Pathway Phrase (template with your meanings)\")\n",
    "        gnh_top    = gr.Text(label=\"Top GNH Indicators (Top 5)\")\n",
    "\n",
    "    gnh_plot = gr.Plot(label=\"GNH Similarity\")\n",
    "    img_out  = gr.Image(label=\"Pathway image\", type=\"filepath\")\n",
    "    meta_out = gr.Text(label=\"Chosen pathway / colors\")\n",
    "\n",
    "    def _update_ui(seq_choice, mode, *current_values):\n",
    "        return update_prompt_ui(seq_choice, mode, *current_values)\n",
    "\n",
    "    # KEY FIX: Pass current color_boxes values to preserve them when changing mode\n",
    "    seq.change(fn=_update_ui, inputs=[seq, word_mode, *color_boxes], outputs=[legend, *color_boxes])\n",
    "    word_mode.change(fn=_update_ui, inputs=[seq, word_mode, *color_boxes], outputs=[legend, *color_boxes])\n",
    "\n",
    "    run.click(\n",
    "        fn=analyze,\n",
    "        inputs=[inp, seq, word_mode, *color_boxes],\n",
    "        outputs=[sent, emo, acc, phrase_out, gnh_top, gnh_plot, img_out, meta_out, legend, *color_boxes],\n",
    "    )\n",
    "\n",
    "    demo.load(fn=_update_ui, inputs=[seq, word_mode, *color_boxes], outputs=[legend, *color_boxes])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.queue()\n",
    "    demo.launch(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9e175-113b-4dd2-af1e-53beff0806a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac5191-5b7d-4f19-92d1-a054ebb7b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# RGB â†’ English Word Library Similarity\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import wordfreq\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "CSV_PATH = \"la matrice.csv\"\n",
    "TOP_K = 15\n",
    "MAX_WORDS = 50000  # size of word library\n",
    "\n",
    "# ---------- LOAD MODEL ----------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ---------- LOAD COLORS ----------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "required_cols = {\"color\", \"r\", \"g\", \"b\"}\n",
    "if not required_cols.issubset({c.lower() for c in df.columns}):\n",
    "    raise ValueError(\"CSV must contain color, r, g, b columns\")\n",
    "\n",
    "colors = []\n",
    "rgb_values = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    colors.append(str(row[\"color\"]).lower())\n",
    "    rgb_values.append(np.array([row[\"r\"], row[\"g\"], row[\"b\"]], dtype=float))\n",
    "\n",
    "# ---------- RGB â†’ TEXT ----------\n",
    "def rgb_to_text(rgb):\n",
    "    r, g, b = rgb\n",
    "    brightness = np.mean(rgb)\n",
    "\n",
    "    if brightness > 200:\n",
    "        tone = \"bright\"\n",
    "    elif brightness < 80:\n",
    "        tone = \"dark\"\n",
    "    else:\n",
    "        tone = \"muted\"\n",
    "\n",
    "    dominant = [\"red\", \"green\", \"blue\"][np.argmax(rgb)]\n",
    "\n",
    "    return f\"{tone} {dominant} color\"\n",
    "\n",
    "color_texts = [rgb_to_text(rgb) for rgb in rgb_values]\n",
    "\n",
    "# ---------- WORD LIBRARY ----------\n",
    "print(\"Loading English word library...\")\n",
    "words = list(wordfreq.top_n_list(\"en\", MAX_WORDS))\n",
    "word_embeddings = model.encode(words, normalize_embeddings=True)\n",
    "\n",
    "print(f\"Loaded {len(words):,} English words\")\n",
    "\n",
    "# ---------- COLOR EMBEDDINGS ----------\n",
    "color_embeddings = model.encode(color_texts, normalize_embeddings=True)\n",
    "\n",
    "# ---------- SIMILARITY SEARCH ----------\n",
    "results = {}\n",
    "\n",
    "for color, emb in zip(colors, color_embeddings):\n",
    "    sims = cosine_similarity([emb], word_embeddings)[0]\n",
    "    top_idx = sims.argsort()[::-1][:TOP_K]\n",
    "\n",
    "    results[color] = [(words[i], float(sims[i])) for i in top_idx]\n",
    "\n",
    "# ---------- DISPLAY ----------\n",
    "for color, matches in results.items():\n",
    "    print(f\"\\nðŸŽ¨ {color.upper()}\")\n",
    "    for word, score in matches:\n",
    "        print(f\"  {word:<18} {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5ac1f-0f17-4e44-a973-d68a43322fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
